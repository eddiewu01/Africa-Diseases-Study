{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from simplejson import loads, dumps\n",
    "from tweepy.streaming import StreamListener\n",
    "import ast\n",
    "consumer_key = 'fhHdOl6iEQjhCdsOEbKckdz15'\n",
    "consumer_sec = 'xsBg1j04Oam2nKWcNHW3ioH8fPwOyYHgQdm3cuQDs7tWLQfVQb'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_sec)\n",
    "access_token = '1146859238-dowHot8BUaoAD2GaF8c4mdUSucWHvrjk95G5uVP'\n",
    "access_token_sec = 'EVoHQ1rbzOGHw6eyYO6F7nioSWqsWFbm1DJ5QptdLEz29'\n",
    "auth.set_access_token(access_token, access_token_sec)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "#public_tweets = api.home_timeline()\n",
    "# for tweet in public_tweets:\n",
    "#     print tweet.text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing structures for extracting tweets\n",
    "result = []\n",
    "unique_tweet = {}\n",
    "\n",
    "# loading from previous structures\n",
    "with open('tweet.json') as json_data:\n",
    "    result = json.load(json_data)\n",
    "\n",
    "for tweet in result:\n",
    "    unique_tweet[tweet['tweet_id']] = 1\n",
    "#     since_id_march4 = tweet['tweet_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2061, 2707)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many unique individuals/organizations we have so far\n",
    "len(dict((v['user_id'],v) for v in result).values()), len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# api.search function wrapper\n",
    "def api_search(result, unique_tweet, place_id, query_term):\n",
    "#     places = api.geo_search(query=query_country, granularity=\"country\")\n",
    "#     place_id = places[0].id\n",
    "#     #print('cancer ' + \"place:%s\" % place_id)\n",
    "    print query_term\n",
    "    tweets = api.search(q= query_term + \" place:%s\" % place_id, since_id = 895384637974990849, \n",
    "                       tweet_mode = 'extended') # arbitrary id from years ago\n",
    "    for tweet in tweets:\n",
    "        if not tweet.full_text.startswith('RT @'):\n",
    "            print tweet.full_text + \" | \" + tweet.place.name if tweet.place else \"Undefined place\"\n",
    "            print tweet.user.screen_name, tweet.user.id, tweet.user.name\n",
    "            print tweet.place.country\n",
    "            if tweet.id not in unique_tweet:     \n",
    "                result.append({\n",
    "                    'tweet_text': tweet.full_text, \n",
    "                    'tweet_place': tweet.place.name,\n",
    "                    'tweet_country': tweet.place.country,\n",
    "                    'tweet_id': tweet.id,\n",
    "                    'user_screen_name': tweet.user.screen_name,\n",
    "                    'user_name': tweet.user.name,\n",
    "                    'user_id': tweet.user.id,\n",
    "                    'tweet_time': str(tweet.created_at),\n",
    "                })\n",
    "                unique_tweet[tweet.id] = 1\n",
    "                \n",
    "        elif hasattr(tweet, 'retweeted_status'):\n",
    "            if tweet.id not in unique_tweet:     \n",
    "                result.append({\n",
    "                    'tweet_text': 'RT @' +info.retweeted_status.user.screen_name + ': ' + info.retweeted_status.full_text, \n",
    "                    'tweet_place': tweet.place.name,\n",
    "                    'tweet_country': tweet.place.country,\n",
    "                    'tweet_id': tweet.id,\n",
    "                    'user_screen_name': tweet.user.screen_name,\n",
    "                    'user_name': tweet.user.name,\n",
    "                    'user_id': tweet.user.id,\n",
    "                    'tweet_time': str(tweet.created_at),\n",
    "                })\n",
    "                unique_tweet[tweet.id] = 1\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get all the past tweets to be full text (one time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnew_result = []\\ni = 1\\nfor tweet in result:\\n    print(i)\\n    i+=1\\n    try:\\n        info = api.get_status(tweet[\\'tweet_id\\'], tweet_mode=\\'extended\\')\\n        print info.full_text\\n        if not info.full_text.startswith(\\'RT @\\'):\\n            print(\"not retweeted\")\\n            tweet[\\'tweet_text\\'] = info.full_text\\n            print(tweet[\\'tweet_text\\'] == info.full_text)\\n            new_result.append(tweet)\\n        elif hasattr(info, \\'retweeted_status\\'):\\n            print(\"retweeted\")\\n            tweet[\\'tweet_text\\'] = \\'RT @\\' +info.retweeted_status.user.screen_name + \\': \\' + info.retweeted_status.full_text\\n            print(tweet[\\'tweet_text\\'] == info.retweeted_status.full_text)\\n            new_result.append(tweet)\\n        else:\\n            continue\\n    except:\\n        break\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "new_result = []\n",
    "i = 1\n",
    "for tweet in result:\n",
    "    print(i)\n",
    "    i+=1\n",
    "    try:\n",
    "        info = api.get_status(tweet['tweet_id'], tweet_mode='extended')\n",
    "        print info.full_text\n",
    "        if not info.full_text.startswith('RT @'):\n",
    "            print(\"not retweeted\")\n",
    "            tweet['tweet_text'] = info.full_text\n",
    "            print(tweet['tweet_text'] == info.full_text)\n",
    "            new_result.append(tweet)\n",
    "        elif hasattr(info, 'retweeted_status'):\n",
    "            print(\"retweeted\")\n",
    "            tweet['tweet_text'] = 'RT @' +info.retweeted_status.user.screen_name + ': ' + info.retweeted_status.full_text\n",
    "            print(tweet['tweet_text'] == info.retweeted_status.full_text)\n",
    "            new_result.append(tweet)\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(new_result), new_result[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# saving to different file(s)\\njs = json.dumps(new_result, sort_keys=True, indent=4, separators=(',', ': '))\\nwith open('piece.json', 'w+') as f:\\n    f.write(js)\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# saving to different file(s)\n",
    "js = json.dumps(new_result, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "with open('piece.json', 'w+') as f:\n",
    "    f.write(js)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using API.search function to get past tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place(_api=<tweepy.api.API object at 0x10d1df990>, country_code=u'ZA', url=u'https://api.twitter.com/1.1/geo/id/dd9c0d7d7e07eb49.json', country=u'South Africa', place_type=u'country', bounding_box=BoundingBox(_api=<tweepy.api.API object at 0x10d1df990>, type=u'Polygon', coordinates=[[[16.4475932, -34.8342468], [16.4475932, -22.1247236], [32.8922934, -22.1247236], [32.8922934, -34.8342468], [16.4475932, -34.8342468]]]), contained_within=[], centroid=[26.128478132597408, -28.4794852], full_name=u'South Africa', attributes={}, id=u'dd9c0d7d7e07eb49', name=u'South Africa')\n",
      "cancer\n",
      "Women: h-\n",
      "\n",
      "'Not all men's Twitter: NOT ALL MEN!! FEMINISM IS CANCER!! BE ANGRY AT THE MEN WHO HURT YOU! https://t.co/L3uH2edEjs | Johannesburg\n",
      "Felicity_M2 618152582 LeviOsa Not LevioSA\n",
      "South Africa\n",
      "Annual Pap Smear done ✅. Ladies it’s so important to get your cervix checked to ensure that you are cleared of any cervical cancer! | Sandton\n",
      "msnoseepoh 175726597 IG: msnoseepoh\n",
      "South Africa\n",
      "@relay_ndayi He's sickly, fighting cancer. | Randburg\n",
      "RulzKay1 484522527 Nceba S. Radebe\n",
      "South Africa\n",
      "Gents please test for Prostate Cancer. That shit be taking leading men in our communities. | Diepkloof\n",
      "The_DonHimself 92541608 Linda Motaung\n",
      "South Africa\n",
      "tumor\n",
      "tumour\n",
      "Health Tips - Listening to music frequently will reduce the risk of a brain tumour over the course of your life.\n",
      "\n",
      "Like, Comment &amp; Share if you agree! #Health #TshwaneHEA\n",
      "\n",
      "Interested in more tips? Like our page @TshwaneHEA\n",
      "\n",
      "How about Home Schooling? Visit https://t.co/5tIA3Kdw5O https://t.co/a4zAzz199I | Pretoria\n",
      "TshwaneHEA 2789458387 Tshwane Home EDU\n",
      "South Africa\n",
      "@pierredevos The man is terminal - the tumour took his conscience | Sandton\n",
      "sjgrimsley 877257354 Selwyn Grimsley\n",
      "South Africa\n",
      "leukaemia\n",
      "Our 825 kilometre walk is more than two months away, and we've already hit more than 10% of our goal donation! \n",
      "\n",
      "Thank you, your belief in #WalkingForLife saves lives &gt;\n",
      "https://t.co/EY0lXPso8U\n",
      "\n",
      "#SouthAfrica #CapeTown #Donors #StemCells #Leukaemia https://t.co/LD8cWXmUsn | Cape Town\n",
      "DigitalShelfSA 4832991507 Digital Shelf\n",
      "South Africa\n",
      "leukemia\n",
      "lymphoma\n",
      "CML\n",
      "burkitt\n"
     ]
    }
   ],
   "source": [
    "# start collecting here\n",
    "\n",
    "# South Africa\n",
    "places = api.geo_search(query='South Africa', granularity=\"country\")\n",
    "place_id = places[0].id\n",
    "print places[0]\n",
    "south_africa_coordinates = places[0].bounding_box.coordinates\n",
    "#print('cancer ' + \"place:%s\" % place_id)\n",
    "\n",
    "# cancer\n",
    "api_search(result, unique_tweet, place_id, 'cancer')\n",
    "    \n",
    "# tumor\n",
    "api_search(result, unique_tweet, place_id, 'tumor')\n",
    "        \n",
    "# tumour\n",
    "api_search(result, unique_tweet, place_id, 'tumour')\n",
    "        \n",
    "# Leukaemia\n",
    "api_search(result, unique_tweet, place_id, 'leukaemia')\n",
    "        \n",
    "# Leukemia\n",
    "api_search(result, unique_tweet, place_id, 'leukemia')\n",
    "        \n",
    "# Lymphoma\n",
    "api_search(result, unique_tweet, place_id, 'lymphoma')\n",
    "        \n",
    "# CML\n",
    "api_search(result, unique_tweet, place_id, 'CML')\n",
    "        \n",
    "# Burkitt\n",
    "api_search(result, unique_tweet, place_id, 'burkitt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer\n",
      "tumor\n",
      "When GOD anoints, He anoints to bless. That you can pull JESUS for sins, tumor and yet you don't believe He can also pull out the debtors or poverty? Issa lie!\n",
      "\n",
      "#TheRelationshipOfTheAnointing | Kiambu\n",
      "NewBreedCity 2880130263 New Breed City (NBC)\n",
      "Kenya\n",
      "tumour\n",
      "@EMS_Kenya in partnership with AMREF Flying Doctors, has carried out an air evacuation for a five-month old baby with a congenital extra-cranial tumour from Mandera to Nairobi for  specialized medical treatment. https://t.co/pm4ceAzVHE | Nairobi\n",
      "KenyaRedCross 138708473 Kenya Red Cross\n",
      "Kenya\n",
      "Leukaemia\n",
      "leukemia\n",
      "Smoking causes cancers of the  \n",
      "1 lung, \n",
      "2 esophagus, \n",
      "3 larynx, \n",
      "4 mouth, \n",
      "5 throat, \n",
      "6 kidney, \n",
      "7 bladder, \n",
      "8 liver,  \n",
      "9 pancreas, \n",
      "10 stomach, \n",
      "11 cervix, \n",
      "12  colon, \n",
      "13 rectum, as well as \n",
      "14 acute myeloid  leukemia | Kenya\n",
      "andrewsuleh 1901033312 Dr Andrew Suleh MD\n",
      "Kenya\n",
      "lymphoma\n",
      "CML\n",
      "burkitt\n"
     ]
    }
   ],
   "source": [
    "# Kenya\n",
    "places = api.geo_search(query='Kenya', granularity=\"country\")\n",
    "place_id = places[0].id\n",
    "kenya_coordinates = places[0].bounding_box.coordinates\n",
    "\n",
    "# cancer\n",
    "api_search(result, unique_tweet, place_id, 'cancer')\n",
    "    \n",
    "# tumor\n",
    "api_search(result, unique_tweet, place_id, 'tumor')\n",
    "        \n",
    "# tumour\n",
    "api_search(result, unique_tweet, place_id, 'tumour')\n",
    "        \n",
    "# Leukaemia\n",
    "api_search(result, unique_tweet, place_id, 'Leukaemia')\n",
    "        \n",
    "# Leukemia\n",
    "api_search(result, unique_tweet, place_id, 'leukemia')\n",
    "        \n",
    "# Lymphoma\n",
    "api_search(result, unique_tweet, place_id, 'lymphoma')\n",
    "        \n",
    "# CML\n",
    "api_search(result, unique_tweet, place_id, 'CML')\n",
    "        \n",
    "# Burkitt\n",
    "api_search(result, unique_tweet, place_id, 'burkitt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer\n",
      "Little girl with cancer needs your donations to fund her care.\n",
      "\n",
      "Twitter please help. Retweet. https://t.co/ip9Z6SdEPC | Lagos\n",
      "D_CHYKE 288777053 Chike Opara\n",
      "Nigeria\n",
      "What else? they say carbide ripened fruits causes Cancer and kidney disease. We await when water or air starts causing cancer too. | Kano\n",
      "Princemeek19 608240768 Prince Sani\n",
      "Nigeria\n",
      "7. Reduces drastically menstrual cramps and Pre-menstrual syndrome (PMS).\n",
      "8. Reduces the risk of cancer.\n",
      "9. Strengthen the heart's muscle, face and vagina.\n",
      "10. Helps in eliminating stretch marks and scars on facial skin. | Ikeja\n",
      "EkeneMyke 91158082 Ekenedilichukwu\n",
      "Nigeria\n",
      "Stem cells can treat over 134 chronic diseases such as Parkinson's disease, Alzheimer's, leukemia, stroke, heart attack, diabetes, cancer, spinal cord paralysis, others....... This is not a hoax. https://t.co/gUpxQp5ZcU | Ikeja\n",
      "EkeneMyke 91158082 Ekenedilichukwu\n",
      "Nigeria\n",
      "tumor\n",
      "FOR ALL SPORTS INJURIES,THE INDIAN DOCTORS ARE HERE,23RD FRIDAY&amp; SATURDAY 24TH MARCH2018 @ ST.LUCIA HOSPITAL OKE ADO IBADAN OYO STATE NIGERIA IS THE VENUE.KIDNEY,SPINAL,KNEE REPLACEMENT SURGERY, TUMOR,BONES..\n",
      "@SplashFM1055 #IBADAN #SHARDA #India #doctor #SPORTS Call- 08033503920 https://t.co/U8WjORWjwC | Nigeria\n",
      "SportsDiscuz 847855568127766534 Sports Discourse\n",
      "Nigeria\n",
      "tumour\n",
      "leukaemia\n",
      "leukemia\n",
      "@thenff led by @PinnickAmaju visits @NGSuperEagles goalkeeper @Carl_Ikeme ahead of @FIFAWorldCup \n",
      "Invited as a special guest during Eagles game against @England on June 2, they seek his permission 2 perform d customary kick-off.\n",
      "D @Wolves keeper is undergoing treatment 4 leukemia https://t.co/GDjX5GhwMm | Lagos\n",
      "Guarantor2011 323218940 Oni Guarantor\n",
      "Nigeria\n",
      "Stem cells can treat over 134 chronic diseases such as Parkinson's disease, Alzheimer's, leukemia, stroke, heart attack, diabetes, cancer, spinal cord paralysis, others....... This is not a hoax. https://t.co/gUpxQp5ZcU | Ikeja\n",
      "EkeneMyke 91158082 Ekenedilichukwu\n",
      "Nigeria\n",
      "I think Vimini is a character the audience would have loved - a 10yrs old genius dying of leukemia #goosebumps or what? @armiehammer @RealChalamet @CMBYNFilm #cmbyn #elio #oliver #italy | Nigeria\n",
      "d_liketheletter 877108865300660224 Kelani\n",
      "Nigeria\n",
      "lymphoma\n",
      "CML\n",
      "burkitt\n"
     ]
    }
   ],
   "source": [
    "# Nigeria\n",
    "places = api.geo_search(query=\"Nigeria\", granularity=\"country\")\n",
    "place_id = places[0].id\n",
    "nigeria_coordinates = places[0].bounding_box.coordinates\n",
    "#print('cancer ' + \"place:%s\" % place_id)\n",
    "\n",
    "# cancer\n",
    "api_search(result, unique_tweet, place_id, 'cancer')\n",
    "\n",
    "# tumor\n",
    "api_search(result, unique_tweet, place_id, 'tumor')\n",
    "        \n",
    "# tumour\n",
    "api_search(result, unique_tweet, place_id, 'tumour')\n",
    "        \n",
    "# Leukaemia\n",
    "api_search(result, unique_tweet, place_id, 'leukaemia')\n",
    "        \n",
    "# Leukemia\n",
    "api_search(result, unique_tweet, place_id, 'leukemia')\n",
    "        \n",
    "# Lymphoma\n",
    "api_search(result, unique_tweet, place_id, 'lymphoma')\n",
    "        \n",
    "# CML\n",
    "api_search(result, unique_tweet, place_id, 'CML')\n",
    "        \n",
    "# Burkitt\n",
    "api_search(result, unique_tweet, place_id, 'burkitt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding tweet information to json file\n",
    "js = json.dumps(result, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "with open('tweet.json', 'w+') as f:\n",
    "    f.write(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# id of tweet on Feb 28th 2018\n",
    "since_id_feb28 = 968897814246936577\n",
    "\n",
    "# id of tweet on march 4th 2018\n",
    "since_id_march4 = 970419633978212352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2713"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current number of tweets\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tumor/tumour (UK vs UK spelling)\n",
    "\n",
    "Leukaemia/Leukemia\n",
    "\n",
    "Lymphoma\n",
    "\n",
    "CML\n",
    "\n",
    "Burkitt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions: \n",
    "1. How to find tweets that are not geotagged, somehow?\n",
    "\n",
    "use streaming API (can get larger amounts of tweets, can use list of keywords, don't include punctuations in the keyword search)\n",
    "\n",
    "dont trust screen_name too much, user_id is more helpful\n",
    "\n",
    "use user location, should be pretty reliable on locating tweets in the spcified location\n",
    "\n",
    "go to user timeline, cannot search by keywords here (3200 tweets of most recent)\n",
    "\n",
    "more than 200,000/300,000 tweets then use database\n",
    "\n",
    "Talk to Yehoda about what to do after extraction of tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using streaming API to get tweets from real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a basic listener that just prints received tweets to stdout.\n",
    "user_locations = [\"South Africa\", \"Kenya\", 'Nigeria', 'Johannesburg, South Africa', \n",
    "                  'Cape Town, South Africa', 'Durban, South Africa', 'Lagos, Nigeria', 'Nairobi, Kenya',\n",
    "                 'Mombasa, Kenya', 'Nakuru, Kenya', 'Kano, Nigeria']\n",
    "class StdOutListener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        #print data\n",
    "        json_data = json.loads(data)\n",
    "        if (json_data['place'] != None and json_data['place']['country'] in [\"South Africa\", \"Kenya\", 'Nigeria']) or json_data['user']['location'] in user_locations:\n",
    "            if json_data['id'] not in unique_tweet:\n",
    "                unique_tweet[json_data['id']] = 1\n",
    "                print \"one more tweet!\"\n",
    "                place = \"\"\n",
    "                country = \"\"\n",
    "                if json_data['place'] == None:\n",
    "                    place = json_data['user']['location']\n",
    "                    country = json_data['user']['location']\n",
    "                else:\n",
    "                    print json_data['place']['name'], json_data['place']['country']\n",
    "                    place = json_data['place']['name']\n",
    "                    country = json_data['place']['country']\n",
    "                    \n",
    "                print json_data\n",
    "                full_text = ''\n",
    "                print json_data['retweeted']\n",
    "                if 'extended_tweet' in json_data:\n",
    "                    print(\"extended_tweet\")\n",
    "                    print json_data['extended_tweet']['full_text']\n",
    "                    full_text = json_data['extended_tweet']['full_text']\n",
    "                else:\n",
    "                    print(\"no extended_tweet\")\n",
    "                    print json_data['text']\n",
    "                    #print json_data['status']['retweeted_status']['text']\n",
    "                    full_text = json_data['text']\n",
    "                print full_text\n",
    "                if not json_data['text'].startswith('RT @') and not json_data['retweeted']:\n",
    "                #if not full_text.startswith('RT @') and not json_data['retweeted']:\n",
    "                    streaming_result = {\n",
    "                        'tweet_text': full_text, \n",
    "                        'tweet_place': place,\n",
    "                        'tweet_country': country,\n",
    "                        'tweet_id': json_data['id'],\n",
    "                        'user_screen_name': json_data['user']['screen_name'],\n",
    "                        'user_name': json_data['user']['name'],\n",
    "                        'user_id': json_data['user']['id'],\n",
    "                        'tweet_time': str(json_data['created_at'])\n",
    "                    }\n",
    "                    print streaming_result\n",
    "                    js = json.dumps(streaming_result, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "                    with open('tweet.json', 'a+') as f:\n",
    "                        f.write(',')\n",
    "                        f.write(js)\n",
    "                        print js\n",
    "                        \n",
    "                else:\n",
    "                    loc_text = ''\n",
    "#                     if json_data['retweeted']:\n",
    "                    if full_text.startswith('RT @'):\n",
    "                        loc_text = full_text\n",
    "                    else:\n",
    "                        loc_text = 'RT @' + json_data['retweeted_status']['user']['screen_name'] + ': ' + full_text\n",
    "                    streaming_result = {\n",
    "                        'tweet_text': loc_text,\n",
    "                        'tweet_place': place,\n",
    "                        'tweet_country': country,\n",
    "                        'tweet_id': json_data['id'],\n",
    "                        'user_screen_name': json_data['user']['screen_name'],\n",
    "                        'user_name': json_data['user']['name'],\n",
    "                        'user_id': json_data['user']['id'],\n",
    "                        'tweet_time': str(json_data['created_at'])\n",
    "                    }\n",
    "                    js = json.dumps(streaming_result, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "                    with open('tweet.json', 'a+') as f:\n",
    "                        f.write(',')\n",
    "                        f.write(js)\n",
    "                        print js\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print status\n",
    "\n",
    "l = StdOutListener()\n",
    "stream = tweepy.Stream(auth, l, tweet_mode='extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[[16.4475932, -34.8342468], [16.4475932, -22.1247236], [32.8922934, -22.1247236], [32.8922934, -34.8342468], [16.4475932, -34.8342468]]], [[[33.9105011, -4.7672356], [33.9105011, 4.631608], [41.8998666, 4.631608], [41.8998666, -4.7672356], [33.9105011, -4.7672356]]], [[[2.6654364, 4.1974055], [2.6654364, 13.8881151], [14.6777951, 13.8881151], [14.6777951, 4.1974055], [2.6654364, 4.1974055]]])\n",
      "[16.4475932, -34.8342468, 32.8922934, -22.1247236, 33.9105011, -4.7672356, 41.8998666, 4.631608, 2.6654364, 4.1974055, 14.6777951, 13.8881151]\n"
     ]
    }
   ],
   "source": [
    "# bounding box coordinates of three countries\n",
    "print(south_africa_coordinates, kenya_coordinates, nigeria_coordinates)\n",
    "\n",
    "# combine them together for streaming purpose\n",
    "coordinates = south_africa_coordinates[0][0] + south_africa_coordinates[0][2] + kenya_coordinates[0][0] + kenya_coordinates[0][2] + nigeria_coordinates[0][0] + nigeria_coordinates[0][2]\n",
    "print coordinates\n",
    "\n",
    "# keywords for search\n",
    "keywords = ['cancer', 'tumor', 'tumour', 'leukaemia', 'leukemia', 'lymphoma', 'cml', 'burkitt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.filter(track = keywords)#locations = coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly sampling 250 tweets (with no retweets RT and no bot tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_no_RT = [i for i in result if not i['tweet_text'].startswith('RT')]\n",
    "cleaned_result = [i for i in result_no_RT if 'More for Cancer https://t.co' not in i['tweet_text']]\n",
    "random_samples = np.random.choice(cleaned_result, size=250, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardwu/anaconda3/envs/py27/lib/python2.7/site-packages/docx/styles/styles.py:54: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
      "  warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# adding random tweets information to word file\n",
    "from docx import Document\n",
    "#js = json.dumps(random_samples, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "document = Document()\n",
    "for item in random_samples:\n",
    "    document.add_paragraph(item['tweet_text'], style='ListNumber')\n",
    "\n",
    "document.save('random_tweets.docx')\n",
    "\n",
    "# with open('random_tweets.json', 'w+') as f:\n",
    "#     f.write(js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the specific kinds of diseases being discussed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
